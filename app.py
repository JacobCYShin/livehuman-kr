'''
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Client (Browser)  â”‚
                        â”‚  - WebRTC Dashboardâ”‚
                        â”‚  - API Controller  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ Offer SDP
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        aiohttp Server      â”‚
                    â”‚     (WebRTC + REST API)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  build_nerfreal()    â”‚                    â”‚  REST API Endpoints     â”‚
â”‚  â””â”€â”€ Load Model      â”‚                    â”‚  - /human               â”‚
â”‚  â””â”€â”€ Load Avatar     â”‚                    â”‚  - /humanaudio          â”‚
â”‚  â””â”€â”€ Warm-up         â”‚                    â”‚  - /set_audiotype       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  - /record              â”‚
          â”‚                                 â”‚  - /is_speaking         â”‚
          â–¼                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
 â”‚  LipReal / MuseReal /  â”‚                            â–¼
 â”‚  NeRFReal (BaseReal)   â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  â””â”€â”€ ASR (LipASR)      â”‚                â”‚    TTS (EdgeTTS, XTTS ë“±)    â”‚
 â”‚  â””â”€â”€ TTS (BaseTTS)     â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚  â””â”€â”€ inference()       â”‚                             â”‚
 â”‚  â””â”€â”€ render()          â”‚ <â”€â”€â”€â”€â”€â”€ call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         WebRTC PeerConnection (aiortc)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ audio_track â† HumanPlayer.audio       â”‚  â”‚
â”‚  â”‚ video_track â† HumanPlayer.video       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

êµ¬ì„±ìš”ì†Œ | ì—­í• 
Client | WebRTC ëŒ€ì‹œë³´ë“œ or API ìš”ì²­ì
aiohttp | WebRTC offer ì²˜ë¦¬ ë° REST API
build_nerfreal() | ëª¨ë¸/ì•„ë°”íƒ€ ë¡œë”© ë° ë””ì§€í„¸ íœ´ë¨¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
BaseReal ê³„ì—´ | LipReal, MuseReal ë“± ë””ì§€í„¸ íœ´ë¨¼ ë¡œì§
ASR, TTS | ì˜¤ë””ì˜¤ ë¶„ì„ ë° í•©ì„± (ì…ë ¥ í…ìŠ¤íŠ¸ â†’ ìŒì„±)
inference() | Wav2Lip ë“± ì… ëª¨ì–‘ ìƒì„± (ìŒì„± + ì–¼êµ´)
render() | ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ WebRTC íŠ¸ë™ìœ¼ë¡œ í‘¸ì‹œ
HumanPlayer | aiortcìš© ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ track ìƒì„±ê¸°
WebRTC PC | ë¸Œë¼ìš°ì €ì™€ ë¯¸ë””ì–´ íŠ¸ë™ ì†¡ìˆ˜ì‹ 

'''
# Windows í™˜ê²½ì—ì„œ UTF-8 ì¸ì½”ë”©ì„ ê°•ì œë¡œ ì„¤ì • (í„°ë¯¸ë„ í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€ìš©)
# chcp 65001

# ì‹¤í–‰ ì˜ˆì‹œ: íŠ¹ì • ëª¨ë¸ ë° ì•„ë°”íƒ€ë¡œ app.py ì‹¤í–‰
# python app.py --transport webrtc --model wav2lip --avatar_id wav2lip256_avatar1
# python app.py --transport webrtc --model wav2lip --avatar_id wav2lip512_taeri
'''
conda activate nerfstream
chcp 65001 
python app.py --transport webrtc --model wav2lip --avatar_id wav2lip_taeri
'''
###############################################################################
#  LiveTalking í”„ë¡œì íŠ¸ ë¼ì´ì„ ìŠ¤ ë° ì €ì‘ê¶Œ ì •ë³´
###############################################################################

# ì„œë²„ ë°±ì—”ë“œ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from flask import Flask, render_template, send_from_directory, request, jsonify
from flask_sockets import Sockets  # WebSocket ì§€ì›ìš© (í˜„ì¬ëŠ” ì‚¬ìš© ì•ˆ í•¨)
import base64
import json
import re
import numpy as np
from threading import Thread, Event
import torch.multiprocessing as mp  # PyTorch ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©

# WebRTC ë° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from aiohttp import web
import aiohttp
import aiohttp_cors  # CORS ì„¤ì •ì„ ìœ„í•œ aiohttp í™•ì¥
from aiortc import RTCPeerConnection, RTCSessionDescription  # WebRTC ì—°ê²° êµ¬ì„± ìš”ì†Œ
from aiortc.rtcrtpsender import RTCRtpSender

# ë‚´ë¶€ ëª¨ë“ˆ - ë””ì§€í„¸ íœ´ë¨¼ ë¡œì§
from webrtc import HumanPlayer  # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬
from basereal import BaseReal    # ë””ì§€í„¸íœ´ë¨¼ ê¸°ë°˜ í´ë˜ìŠ¤
from llm import llm_response     # LLM ê¸°ë°˜ ì‘ë‹µ ìƒì„± í•¨ìˆ˜

# ê¸°íƒ€ ìœ í‹¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import argparse  # ì»¤ë§¨ë“œë¼ì¸ ì˜µì…˜ íŒŒì‹±
import random
import shutil
import asyncio
import torch
from typing import Dict
from logger import logger  # ì»¤ìŠ¤í…€ ë¡œê¹… ìœ í‹¸

# Flask ì•± ìƒì„±
app = Flask(__name__)

# ë””ì§€í„¸ íœ´ë¨¼ ì¸ìŠ¤í„´ìŠ¤ë¥¼ sessionid ë³„ë¡œ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
nerfreals: Dict[int, BaseReal] = {}

# ì‹¤í–‰ ì‹œ ì˜µì…˜ ê°’ê³¼ ëª¨ë¸, ì•„ë°”íƒ€ ê°ì²´ ì €ì¥ìš© ì „ì—­ ë³€ìˆ˜
opt = None
model = None
avatar = None

##### WebRTC ê´€ë ¨ ì „ì—­ ì„¸ì…˜ ëª©ë¡ #####
pcs = set()  # í˜„ì¬ ì—°ê²°ëœ ëª¨ë“  WebRTC PeerConnectionì„ ì €ì¥

# Nìë¦¬ì˜ ë¬´ì‘ìœ„ ìˆ«ìë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì„¸ì…˜ ID ìš©)
def randN(N) -> int:
    min = pow(10, N - 1)
    max = pow(10, N)
    return random.randint(min, max - 1)

# ì„¸ì…˜ë³„ ë””ì§€í„¸ íœ´ë¨¼ ê°ì²´ ìƒì„± í•¨ìˆ˜
def build_nerfreal(sessionid: int) -> BaseReal:
    opt.sessionid = sessionid
    # ì„ íƒëœ ëª¨ë¸ ì¢…ë¥˜ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ ë¡œë“œ
    if opt.model == 'wav2lip':
        from lipreal import LipReal
        nerfreal = LipReal(opt, model, avatar)
    elif opt.model == 'musetalk':
        from musereal import MuseReal
        nerfreal = MuseReal(opt, model, avatar)
    elif opt.model == 'ernerf':
        from nerfreal import NeRFReal
        nerfreal = NeRFReal(opt, model, avatar)
    elif opt.model == 'ultralight':
        from lightreal import LightReal
        nerfreal = LightReal(opt, model, avatar)
    return nerfreal

# WebRTC offer ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë¹„ë™ê¸° HTTP í•¸ë“¤ëŸ¬
# WebRTCì—ì„œ offer ìš”ì²­ì€ "ë‚˜ ì—°ê²°í•  ì¤€ë¹„ ëëŠ”ë°, ë„ˆëŠ” ì–´ë•Œ?" ë¼ëŠ” ì‹ì˜ ì´ˆê¸° ì—°ê²° ì œì•ˆ ë©”ì‹œì§€ì…ë‹ˆë‹¤. ì´ê±´ WebRTCì˜ ì‹œê·¸ë„ë§(Signaling) ê³¼ì •ì˜ í•µì‹¬
'''
[1] ìœ ì €ê°€ offer ìš”ì²­ (ë¸Œë¼ìš°ì €)
    â”‚
    â–¼
[2] ì„œë²„ì—ì„œ offer ì²˜ë¦¬ (offer í•¨ìˆ˜)
    â”‚
    â”œâ”€[a] ë””ì§€í„¸ íœ´ë¨¼ ê°ì²´ ìƒì„± (build_nerfreal)
    â”‚       â†“
    â”‚     HumanPlayer(nerfreals[sessionid])
    â”‚       â”œâ”€ audio (ê°€ìƒ ë§ˆì´í¬)
    â”‚       â””â”€ video (ê°€ìƒ ì¹´ë©”ë¼)
    â”‚
    â”œâ”€[b] WebRTC ì—°ê²° ìƒì„± (RTCPeerConnection)
    â”‚       â”œâ”€ pc.addTrack(audio)
    â”‚       â””â”€ pc.addTrack(video)
    â”‚
    â”œâ”€[c] ì½”ë± ìš°ì„ ìˆœìœ„ ì„¤ì • (setCodecPreferences)
    â”‚
    â”œâ”€[d] answer ìƒì„± ë° í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
    â”‚
    â–¼
[3] í´ë¼ì´ì–¸íŠ¸ì—ì„œ answer ìˆ˜ì‹  â†’ WebRTC ì—°ê²° ì™„ë£Œ
    â”‚
    â–¼
[4] ë””ì§€í„¸ íœ´ë¨¼ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ê°€ ì‹¤ì‹œê°„ ì „ì†¡ë¨
    â”‚
    â–¼
[5] ì—°ê²° ì¢…ë£Œ/ì‹¤íŒ¨ ê°ì§€ ì‹œ:
    â””â”€ connectionStatechange ì½œë°± â†’ ìì› ì •ë¦¬

'''
async def offer(request):
    # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° SDP offer ìˆ˜ì‹ 
    params = await request.json()
    offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])

    # ìµœëŒ€ ì„¸ì…˜ ìˆ˜ ì´ˆê³¼ ì‹œ ì—°ê²° ê±°ë¶€
    if len(nerfreals) >= opt.max_session:
        logger.info('reach max session')
        return -1

    # ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„±
    sessionid = randN(6)
    logger.info('sessionid=%d', sessionid)

    # ë””ì§€í„¸ íœ´ë¨¼ ê°ì²´ ì´ˆê¸°í™” (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰)
    nerfreals[sessionid] = None
    nerfreal = await asyncio.get_event_loop().run_in_executor(None, build_nerfreal, sessionid)
    nerfreals[sessionid] = nerfreal

    # WebRTC ì—°ê²° ê°ì²´ ìƒì„±
    pc = RTCPeerConnection()
    pcs.add(pc)

    # ì—°ê²° ìƒíƒœ ë³€ê²½ ì½œë°± ë“±ë¡
    @pc.on("connectionstatechange")
    async def on_connectionstatechange():
        logger.info("Connection state is %s" % pc.connectionState)
        # ì—°ê²° ì¢…ë£Œ ë˜ëŠ” ì‹¤íŒ¨ ì‹œ cleanup
        if pc.connectionState == "failed":
            await pc.close()
            pcs.discard(pc)
            del nerfreals[sessionid]
        if pc.connectionState == "closed":
            pcs.discard(pc)
            del nerfreals[sessionid]

    # ë””ì§€í„¸ íœ´ë¨¼ìœ¼ë¡œë¶€í„° ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŠ¸ë™ ìƒì„±
    player = HumanPlayer(nerfreals[sessionid])
    audio_sender = pc.addTrack(player.audio)
    video_sender = pc.addTrack(player.video)

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ ì½”ë± ì„¤ì •
    capabilities = RTCRtpSender.getCapabilities("video")
    preferences = list(filter(lambda x: x.name == "H264", capabilities.codecs))
    preferences += list(filter(lambda x: x.name == "VP8", capabilities.codecs))
    preferences += list(filter(lambda x: x.name == "rtx", capabilities.codecs))
    transceiver = pc.getTransceivers()[1]
    transceiver.setCodecPreferences(preferences)

    # í´ë¼ì´ì–¸íŠ¸ offer ì„¤ì • ì ìš© ë° ì‘ë‹µ answer ìƒì„±
    await pc.setRemoteDescription(offer)
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)
    # ICEë€? : ì—°ê²° ê°€ëŠ¥í•œ IP/í¬íŠ¸ ì¡°í•©, ì—°ê²° ê²½ë¡œ í›„ë³´ë“¤

    # í´ë¼ì´ì–¸íŠ¸ì— answer + sessionid ì‘ë‹µ ë°˜í™˜
    return web.Response(
        content_type="application/json",
        text=json.dumps({
            "sdp": pc.localDescription.sdp,
            "type": pc.localDescription.type,
            "sessionid": sessionid
        }),
    )

# ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ (echo ë˜ëŠ” chat)
async def human(request):
    # raw HTTP body (bytes) â†’ JSON ë¬¸ìì—´ â†’ Python dict
    params = await request.json()  # ìš”ì²­ ë°”ë””ì—ì„œ JSON íŒŒì‹±

    sessionid = params.get('sessionid', 0)

    # ì‚¬ìš©ìê°€ ì¤‘ê°„ì— ëŠê¸°ë¥¼ ìš”ì²­í•œ ê²½ìš°: í˜„ì¬ ìŒì„± ì¶œë ¥ ì·¨ì†Œ
    if params.get('interrupt'):
        nerfreals[sessionid].flush_talk()

    # echo íƒ€ì…: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥
    if params['type'] == 'echo':
        nerfreals[sessionid].put_msg_txt(params['text'])

    # chat íƒ€ì…: LLMì„ í†µí•´ ì‘ë‹µ ìƒì„±
    elif params['type'] == 'chat':
        res = await asyncio.get_event_loop().run_in_executor(
            None, llm_response, params['text'], nerfreals[sessionid]
        )
        # (ì„ íƒ) ìƒì„±ëœ ì‘ë‹µì„ speak queueì— ë„£ìœ¼ë ¤ë©´ ì•„ë˜ ë¼ì¸ í™œì„±í™”
        # nerfreals[sessionid].put_msg_txt(res)
    ''' await asyncio.get_event_loop().run_in_executor ì¶”ê°€ê°€ ì„¤ëª…
    [ë©”ì¸ asyncio ë£¨í”„]     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â†“                           â†“
    await run_in_executor(...)   â†’  [ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ] â†’ some_function() ì‹¤í–‰
        â†“                           â†‘
    ë‹¤ë¥¸ ì½”ë£¨í‹´ë„ ì‹¤í–‰ ì¤‘        ì‘ì—… ì™„ë£Œë˜ë©´ ê²°ê³¼ ë°˜í™˜
    '''

    return web.Response(
        content_type="application/json",
        text=json.dumps({"code": 0, "data": "ok"})
    )


# ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
async def humanaudio(request):
    try:
        form = await request.post()  # multipart/form-data íŒŒì‹±
        sessionid = int(form.get('sessionid', 0))

        fileobj = form["file"]  # íŒŒì¼ ê°ì²´ íšë“
        filename = fileobj.filename
        filebytes = fileobj.file.read()  # ë°”ì´íŠ¸ë¡œ ì½ê¸°

        # ë””ì§€í„¸íœ´ë¨¼ ê°ì²´ì— ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ì „ë‹¬
        nerfreals[sessionid].put_audio_file(filebytes)

        return web.Response(
            content_type="application/json",
            text=json.dumps({"code": 0, "msg": "ok"})
        )
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨ ì‘ë‹µ
        return web.Response(
            content_type="application/json",
            text=json.dumps({"code": -1, "msg": "err", "data": str(e)})
        )


# í˜„ì¬ ì˜¤ë””ì˜¤ íƒ€ì… (ì˜ˆ: ì‹¤ì‹œê°„ / ì°¸ì¡° ê¸°ë°˜ ë“±) ì„¤ì •
async def set_audiotype(request):
    params = await request.json()
    sessionid = params.get('sessionid', 0)

    # ì˜¤ë””ì˜¤ ìƒíƒœ ë° ì´ˆê¸°í™” ì—¬ë¶€ ì „ë‹¬
    nerfreals[sessionid].set_curr_state(params['audiotype'], params['reinit'])

    return web.Response(
        content_type="application/json",
        text=json.dumps({"code": 0, "data": "ok"})
    )


# ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ ìš”ì²­ ì²˜ë¦¬
async def record(request):
    params = await request.json()
    sessionid = params.get('sessionid', 0)

    if params['type'] == 'start_record':
        nerfreals[sessionid].start_recording()
    elif params['type'] == 'end_record':
        nerfreals[sessionid].stop_recording()

    return web.Response(
        content_type="application/json",
        text=json.dumps({"code": 0, "data": "ok"})
    )


# í˜„ì¬ ë””ì§€í„¸íœ´ë¨¼ì´ ë§í•˜ê³  ìˆëŠ” ìƒíƒœì¸ì§€ ì—¬ë¶€ ë°˜í™˜
async def is_speaking(request):
    params = await request.json()
    sessionid = params.get('sessionid', 0)

    return web.Response(
        content_type="application/json",
        text=json.dumps({
            "code": 0,
            "data": nerfreals[sessionid].is_speaking()
        })
    )


# ì„œë²„ ì¢…ë£Œ ì‹œ ëª¨ë“  WebRTC ì—°ê²° ì¢…ë£Œ ì²˜ë¦¬
async def on_shutdown(app):
    # ëª¨ë“  peer connection ì¢…ë£Œ
    coros = [pc.close() for pc in pcs]
    await asyncio.gather(*coros)
    pcs.clear()


# ì™¸ë¶€ ì„œë²„ì— POST ìš”ì²­ì„ ë¹„ë™ê¸°ë¡œ ë³´ë‚´ëŠ” ìœ í‹¸ í•¨ìˆ˜
async def post(url, data):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, data=data) as response:
                return await response.text()
    except aiohttp.ClientError as e:
        logger.info(f'Error: {e}')


# ì™¸ë¶€ push_urlë¡œ WebRTC offer â†’ answer ì²˜ë¦¬í•˜ëŠ” ë‹¨ë… ì‹¤í–‰ íë¦„ (ë¹„í‘œì¤€ìš©ë„)
async def run(push_url, sessionid):
    # ë””ì§€í„¸ íœ´ë¨¼ ìƒì„±
    nerfreal = await asyncio.get_event_loop().run_in_executor(None, build_nerfreal, sessionid)
    nerfreals[sessionid] = nerfreal

    pc = RTCPeerConnection()
    pcs.add(pc)

    @pc.on("connectionstatechange")
    async def on_connectionstatechange():
        logger.info("Connection state is %s" % pc.connectionState)
        if pc.connectionState == "failed":
            await pc.close()
            pcs.discard(pc)

    # ë””ì§€í„¸íœ´ë¨¼ìœ¼ë¡œë¶€í„° ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŠ¸ë™ ìƒì„±
    player = HumanPlayer(nerfreals[sessionid])
    audio_sender = pc.addTrack(player.audio)
    video_sender = pc.addTrack(player.video)

    # offer ìƒì„± â†’ remote answer ìˆ˜ì‹  â†’ ì—°ê²° ì™„ë£Œ
    await pc.setLocalDescription(await pc.createOffer())
    answer = await post(push_url, pc.localDescription.sdp)
    await pc.setRemoteDescription(RTCSessionDescription(sdp=answer, type='answer'))


# (ì°¸ê³ ) ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ - Intel MKL ê°•ì œ ì‚¬ìš© ë“±
# os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'
# os.environ['MULTIPROCESSING_METHOD'] = 'forkserver'

                                           
if __name__ == '__main__':
    # PyTorch ë©€í‹°í”„ë¡œì„¸ì‹± ì´ˆê¸°í™” ë°©ì‹ ì„¤ì • (Windows í˜¸í™˜ ìœ„í•´ 'spawn' ì‚¬ìš©)
    mp.set_start_method('spawn')

    # ëª…ë ¹ì¤„ ì¸ì ì„¤ì •
    parser = argparse.ArgumentParser()

    # í¬ì¦ˆ, ì–¼êµ´ ê·¼ìœ¡(ëˆˆ ê¹œë¹¡ì„), ìƒì²´ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
    parser.add_argument('--pose', type=str, default="data/data_kf.json", help="transforms.json, pose source")
    parser.add_argument('--au', type=str, default="data/au.csv", help="eye blink area")
    parser.add_argument('--torso_imgs', type=str, default="", help="torso images path")

    # -OëŠ” ì—¬ëŸ¬ ìµœì í™” ì˜µì…˜ì„ í•œêº¼ë²ˆì— ì ìš© (fp16 + cuda_ray + exp_eye)
    parser.add_argument('-O', action='store_true', help="equals --fp16 --cuda_ray --exp_eye")

    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„° ë²”ìœ„
    parser.add_argument('--data_range', type=int, nargs='*', default=[0, -1])
    parser.add_argument('--workspace', type=str, default='data/video')
    parser.add_argument('--seed', type=int, default=0)

    ### í•™ìŠµ ê´€ë ¨ ì˜µì…˜
    parser.add_argument('--ckpt', type=str, default='data/pretrained/ngp_kf.pth')  # ì‚¬ì „í•™ìŠµ ì²´í¬í¬ì¸íŠ¸

    # ë ˆì´ ìƒ˜í”Œë§ ê´€ë ¨ (NeRF ê´€ë ¨ ì˜µì…˜)
    parser.add_argument('--num_rays', type=int, default=4096 * 16)
    parser.add_argument('--cuda_ray', action='store_true')
    parser.add_argument('--max_steps', type=int, default=16)
    parser.add_argument('--num_steps', type=int, default=16)
    parser.add_argument('--upsample_steps', type=int, default=0)
    parser.add_argument('--update_extra_interval', type=int, default=16)
    parser.add_argument('--max_ray_batch', type=int, default=4096)

    ### ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
    parser.add_argument('--warmup_step', type=int, default=10000)
    parser.add_argument('--amb_aud_loss', type=int, default=1)
    parser.add_argument('--amb_eye_loss', type=int, default=1)
    parser.add_argument('--unc_loss', type=int, default=1)
    parser.add_argument('--lambda_amb', type=float, default=1e-4)

    ### ë„¤íŠ¸ì›Œí¬ ë°±ë³¸ ê´€ë ¨
    parser.add_argument('--fp16', action='store_true')
    parser.add_argument('--bg_img', type=str, default='white')
    parser.add_argument('--fbg', action='store_true')
    parser.add_argument('--exp_eye', action='store_true')
    parser.add_argument('--fix_eye', type=float, default=-1)
    parser.add_argument('--smooth_eye', action='store_true')
    parser.add_argument('--torso_shrink', type=float, default=0.8)

    ### ë°ì´í„°ì…‹ ë¡œë”© ì„¤ì •
    parser.add_argument('--color_space', type=str, default='srgb')
    parser.add_argument('--preload', type=int, default=0)
    parser.add_argument('--bound', type=float, default=1)
    parser.add_argument('--scale', type=float, default=4)
    parser.add_argument('--offset', type=float, nargs='*', default=[0, 0, 0])
    parser.add_argument('--dt_gamma', type=float, default=1/256)
    parser.add_argument('--min_near', type=float, default=0.05)
    parser.add_argument('--density_thresh', type=float, default=10)
    parser.add_argument('--density_thresh_torso', type=float, default=0.01)
    parser.add_argument('--patch_size', type=int, default=1)

    parser.add_argument('--init_lips', action='store_true')
    parser.add_argument('--finetune_lips', action='store_true')
    parser.add_argument('--smooth_lips', action='store_true')

    parser.add_argument('--torso', action='store_true')
    parser.add_argument('--head_ckpt', type=str, default='')

    ### GUI ê´€ë ¨ ì˜µì…˜
    parser.add_argument('--gui', action='store_true')
    parser.add_argument('--W', type=int, default=450)
    parser.add_argument('--H', type=int, default=450)
    parser.add_argument('--radius', type=float, default=3.35)
    parser.add_argument('--fovy', type=float, default=21.24)
    parser.add_argument('--max_spp', type=int, default=1)

    ### ì˜¤ë””ì˜¤ / attention / ê°œë³„ ì½”ë“œ ê´€ë ¨
    parser.add_argument('--att', type=int, default=2)
    parser.add_argument('--aud', type=str, default='')
    parser.add_argument('--emb', action='store_true')
    parser.add_argument('--ind_dim', type=int, default=4)
    parser.add_argument('--ind_num', type=int, default=10000)
    parser.add_argument('--ind_dim_torso', type=int, default=8)
    parser.add_argument('--amb_dim', type=int, default=2)
    parser.add_argument('--part', action='store_true')
    parser.add_argument('--part2', action='store_true')

    parser.add_argument('--train_camera', action='store_true')
    parser.add_argument('--smooth_path', action='store_true')
    parser.add_argument('--smooth_path_window', type=int, default=7)

    ### ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (ASR) ì˜µì…˜
    parser.add_argument('--asr', action='store_true')
    parser.add_argument('--asr_wav', type=str, default='')
    parser.add_argument('--asr_play', action='store_true')
    parser.add_argument('--asr_model', type=str, default='cpierse/wav2vec2-large-xlsr-53-esperanto')
    parser.add_argument('--asr_save_feats', action='store_true')

    # ì˜¤ë””ì˜¤ fps ë° ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì„¤ì •
    parser.add_argument('--fps', type=int, default=50)
    parser.add_argument('-l', type=int, default=10)
    parser.add_argument('-m', type=int, default=8)
    parser.add_argument('-r', type=int, default=10)

    ### ì „ì‹  ì•„ë°”íƒ€ ì„¤ì •
    parser.add_argument('--fullbody', action='store_true')
    parser.add_argument('--fullbody_img', type=str, default='data/fullbody/img')
    parser.add_argument('--fullbody_width', type=int, default=580)
    parser.add_argument('--fullbody_height', type=int, default=1080)
    parser.add_argument('--fullbody_offset_x', type=int, default=0)
    parser.add_argument('--fullbody_offset_y', type=int, default=0)

    # musetalk ì˜µì…˜
    parser.add_argument('--avatar_id', type=str, default='avator_1')
    parser.add_argument('--bbox_shift', type=int, default=5) # only Musetalk
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--customvideo_config', type=str, default='')

    # ìŒì„± í•©ì„± (TTS) ê´€ë ¨
    parser.add_argument('--tts', type=str, default='local')
    parser.add_argument('--REF_FILE', type=str, default='reference.wav')
    parser.add_argument('--REF_TEXT', type=str, default=None)
    parser.add_argument('--TTS_SERVER', type=str, default='http://127.0.0.1:7009')

    # ëª¨ë¸ ë° ì „ì†¡ ë°©ì‹ ì„ íƒ
    parser.add_argument('--model', type=str, default='ernerf')
    parser.add_argument('--transport', type=str, default='rtcpush')
    parser.add_argument('--push_url', type=str, default='http://localhost:1985/rtc/v1/whip/?app=live&stream=livestream')
    parser.add_argument('--max_session', type=int, default=1)
    parser.add_argument('--listenport', type=int, default=8010)

    # ì¸ì íŒŒì‹±
    opt = parser.parse_args()

    # custom video ì„¤ì • json ë¶ˆëŸ¬ì˜¤ê¸°
    opt.customopt = []
    if opt.customvideo_config != '':
        with open(opt.customvideo_config, 'r') as file:
            opt.customopt = json.load(file)

    # ëª¨ë¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ëª¨ë“ˆ import ë° ë¡œë”©
    if opt.model == 'ernerf':
        from nerfreal import NeRFReal, load_model, load_avatar
        model = load_model(opt)
        avatar = load_avatar(opt)

    elif opt.model == 'musetalk':
        from musereal import MuseReal, load_model, load_avatar, warm_up
        logger.info(opt)
        model = load_model()
        avatar = load_avatar(opt.avatar_id)
        warm_up(opt.batch_size, model)

    elif opt.model == 'wav2lip':
        from lipreal import LipReal, load_model, load_avatar, warm_up
        logger.info(opt)
        model = load_model("./models/wav2lip.pth")
        avatar = load_avatar(opt.avatar_id)
        warm_up(opt.batch_size, model, 256)
        # warm_up(opt.batch_size, model, 512)

    elif opt.model == 'ultralight':
        from lightreal import LightReal, load_model, load_avatar, warm_up
        logger.info(opt)
        model = load_model(opt)
        avatar = load_avatar(opt.avatar_id)
        warm_up(opt.batch_size, avatar, 160)

    # RTMP ëª¨ë“œì¼ ê²½ìš° ë³„ë„ ìŠ¤ë ˆë“œë¡œ ë Œë”ë§ ì‹œì‘
    if opt.transport == 'rtmp':
        thread_quit = Event()
        nerfreals[0] = build_nerfreal(0)
        rendthrd = Thread(target=nerfreals[0].render, args=(thread_quit,))
        rendthrd.start()

    # ì›¹ ì„œë²„ ì´ˆê¸°í™”
    appasync = web.Application()
    appasync.on_shutdown.append(on_shutdown)

    # API ë¼ìš°íŒ… ë“±ë¡
    appasync.router.add_post("/offer", offer)
    appasync.router.add_post("/human", human)
    appasync.router.add_post("/humanaudio", humanaudio)
    appasync.router.add_post("/set_audiotype", set_audiotype)
    appasync.router.add_post("/record", record)
    appasync.router.add_post("/is_speaking", is_speaking)
    appasync.router.add_static('/', path='web')

    # CORS í—ˆìš© ì„¤ì •
    cors = aiohttp_cors.setup(appasync, defaults={
        "*": aiohttp_cors.ResourceOptions(
            allow_credentials=True,
            expose_headers="*",
            allow_headers="*",
        )
    })
    for route in list(appasync.router.routes()):
        cors.add(route)

    # transport ëª¨ë“œì— ë”°ë¼ ê¸°ë³¸ í˜ì´ì§€ ì„ íƒ
    pagename = {
        'rtmp': 'echoapi.html',
        'rtcpush': 'rtcpushapi.html'
    }.get(opt.transport, 'webrtcapi.html')

    # ì›¹ ì„œë²„ ì‹œì‘ ë¡œê·¸ ì¶œë ¥ (ì„œë²„ ì ‘ì† URL ì•ˆë‚´)
    logger.info(f"ğŸ“¡ HTTP ì„œë²„ ì‹œì‘: http://<serverip>:{opt.listenport}/{pagename}")
    logger.info(f"ğŸ’¡ WebRTC ì‚¬ìš© ì‹œ ëŒ€ì‹œë³´ë“œ ì ‘ì† ê¶Œì¥: http://<serverip>:{opt.listenport}/dashboard.html")

    # ì›¹ì„œë²„ ì‹¤í–‰ì„ ìœ„í•œ ë¹„ë™ê¸° í•¨ìˆ˜ ì •ì˜
    def run_server(runner):
        # ë³„ë„ì˜ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì„¤ì •
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # ì•± ì‹¤í–‰ ì¤€ë¹„ (ë¼ìš°íŒ…, ë¯¸ë“¤ì›¨ì–´, etc)
        loop.run_until_complete(runner.setup())

        # ì‹¤ì œ TCP ì„œë²„ ë°”ì¸ë”© ë° ì‹œì‘ (listenportë¡œ ìˆ˜ì‹  ëŒ€ê¸°)
        site = web.TCPSite(runner, '0.0.0.0', opt.listenport)
        loop.run_until_complete(site.start())

        # transport ë°©ì‹ì´ 'rtcpush'ì¼ ê²½ìš°: ì§€ì •ëœ push_urlë¡œ ì„¸ì…˜ë³„ ë¹„ë””ì˜¤ í‘¸ì‹œ
        if opt.transport == 'rtcpush':
            for k in range(opt.max_session):
                # ì„¸ì…˜ ë²ˆí˜¸ì— ë”°ë¼ URL êµ¬ë¶„ (stream1, stream2 ë“±)
                push_url = opt.push_url if k == 0 else opt.push_url + str(k)
                # ê° ì„¸ì…˜ë³„ë¡œ run(push_url, sessionid) í˜¸ì¶œ â†’ WebRTC ì—°ê²° ì‹œì‘
                loop.run_until_complete(run(push_url, k))

        # ì„œë²„ ë¬´í•œ ë£¨í”„ ì‹œì‘ (ì‹ í˜¸ê°€ ë“¤ì–´ì˜¬ ë•Œê¹Œì§€ ê³„ì† ëŒ€ê¸°)
        loop.run_forever()

    # aiohttp ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    run_server(web.AppRunner(appasync))
